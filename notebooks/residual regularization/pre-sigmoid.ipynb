{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-27T12:50:53.732127Z",
     "start_time": "2025-11-27T12:50:45.198198Z"
    }
   },
   "source": [
    "from tools.checkpoint import model_from_checkpoint\n",
    "from training.eval import Evaluator\n",
    "from data.data_gen_stream import DistributedDataGenerator\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "model, hparams = model_from_checkpoint(\n",
    "    '/Users/jonathanmiddleton/models/checkpoints/820m-base/20251126T2111-val3.340-step043946-tokens18000281600-run1-final.pt',\n",
    "    device='mps')\n",
    "model.eval()\n",
    "\n",
    "ddg = DistributedDataGenerator(\n",
    "    filename_pattern=\"/Users/jonathanmiddleton/projects/daisy/data/dclm_baseline/dclm_baseline_val_000000.bin\",\n",
    "    sequence_length=8192,\n",
    "    rank=0,\n",
    "    world_size=1,\n",
    "    start_shard=1,\n",
    "    device='mps',\n",
    ")\n",
    "evaluator = Evaluator(\n",
    "            data_generator=ddg,\n",
    "            distributed_enabled=False,\n",
    "            rank=0,\n",
    "            attn_window_len=hparams['train_attention_window_len'],\n",
    "            val_type='pretraining'\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-27 07:50:53,730 WARNING tools.master_logger: [MasterLogger] Falling back to console logging; failed to apply config/logging.yml: [Errno 2] No such file or directory: 'config/logging.yml'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T12:50:53.744065Z",
     "start_time": "2025-11-27T12:50:53.741619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_scalar_views(model):\n",
    "    L = len(model.blocks)\n",
    "    s = model.scalars.view(-1)\n",
    "    skip = s[:L]\n",
    "    lambdas = s[1 * L:3 * L].view(L, 2)\n",
    "    sa_lambdas = s[3 * L:5 * L].view(L, 2)\n",
    "    return skip, lambdas, sa_lambdas\n",
    "\n",
    "def print_scalar_stats(model):\n",
    "    skip, lambdas, sa_lambdas = get_scalar_views(model)\n",
    "    with torch.no_grad():\n",
    "        def stats(x):\n",
    "            return dict(\n",
    "                min=float(x.min()),\n",
    "                max=float(x.max()),\n",
    "                mean=float(x.mean()),\n",
    "                std=float(x.std())\n",
    "            )\n",
    "        print(\"skip_weights:\", stats(skip))\n",
    "        print(\"lambdas:\", stats(lambdas))\n",
    "        print(\"sa_lambdas:\", stats(sa_lambdas))"
   ],
   "id": "bec87f53f77a16bc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T12:50:53.771139Z",
     "start_time": "2025-11-27T12:50:53.768607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_loss(model, total_tokens):\n",
    "    acc_loss = 0\n",
    "    samples = 10\n",
    "    for i in range(samples):\n",
    "        d = evaluator.eval(model=model, schedule=.83)  #.83 pretraining progress from checkpoint\n",
    "        acc_loss += d['val_loss']\n",
    "        print(d)\n",
    "    print(f\"avg loss: {acc_loss/samples}\")\n",
    "\n",
    "def renormalize_scalar_pairs_(model, target_norm=1.0, eps=1e-6):\n",
    "    L = len(model.blocks)\n",
    "    with torch.no_grad():\n",
    "        s = model.scalars.view(-1)\n",
    "        lambdas = s[1 * L:3 * L].view(L, 2)\n",
    "        sa_lambdas = s[3 * L:5 * L].view(L, 2)\n",
    "\n",
    "        lam_norm = lambdas.norm(dim=-1, keepdim=True).clamp_min(eps)\n",
    "        sa_norm = sa_lambdas.norm(dim=-1, keepdim=True).clamp_min(eps)\n",
    "\n",
    "        lambdas.mul_(target_norm / lam_norm)\n",
    "        sa_lambdas.mul_(target_norm / sa_norm)\n",
    "\n",
    "def clone_with_renormalized_scalars(model, target_norm=1.0, eps=1e-6):\n",
    "    import copy\n",
    "    new_model = copy.deepcopy(model)\n",
    "    renormalize_scalar_pairs_(new_model, target_norm=target_norm, eps=eps)\n",
    "    return new_model"
   ],
   "id": "1c4ad5031b8827bf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T12:50:53.782535Z",
     "start_time": "2025-11-27T12:50:53.775798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tools.model_report import build_report, format_report_text\n",
    "\n",
    "total_tokens = 100_000\n",
    "report = build_report(model)\n",
    "print(f\"Model report:\\n{format_report_text(report)}\")"
   ],
   "id": "baacb16f0279f3a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report:\n",
      "=== Checkpoint ===\n",
      "\n",
      "=== Model stats ===\n",
      "parameters (total): 818,932,816 (818932816)\n",
      "parameters (trainable): 818,932,816 (818932816)\n",
      "parameter size: 1660.24 MiB\n",
      "model type: DaisyCore\n",
      "layers: 16\n",
      "\n",
      "parameter dtypes:\n",
      "  float32: 51,511,376 (51511376)\n",
      "  bfloat16: 767,421,440 (767421440)\n",
      "\n",
      "=== Learned scalars (DaisyCore) ===\n",
      "num_layers (inferred): 16\n",
      "threshold for near-zero: 0.001\n",
      "- skip_weights: shape=[16], min=0.08816, max=1, mean=0.8418, std=0.3308\n",
      "  near-zero: 0 elements (0.00%)\n",
      "- lambdas: shape=[16, 2], min=-17.92, max=52.35, mean=13.8, std=16.48\n",
      "  near-zero: 0 elements (0.00%)\n",
      "- sa_lambdas: shape=[16, 2], min=0.5, max=78.92, mean=25.32, std=20.75\n",
      "  near-zero: 0 elements (0.00%)\n",
      "\n",
      "Per-layer (i: skip | lambda | sa_lambda):\n",
      "  00: 1.0000 | [34.2854, 33.2853] | [7.8548, 9.1434]\n",
      "  01: 1.0000 | [0.3191, 52.3514] | [19.9412, 0.5000]\n",
      "  02: 0.2520 | [0.8846, 46.4581] | [21.2987, 18.7501]\n",
      "  03: 1.0000 | [0.8034, 30.4527] | [30.7342, 21.9033]\n",
      "  04: 0.1282 | [0.6627, 28.2102] | [56.7492, 0.5000]\n",
      "  05: 1.0000 | [0.3912, 18.4169] | [42.8384, 13.2726]\n",
      "  06: 0.0882 | [0.7243, 30.1781] | [67.2813, 0.5000]\n",
      "  07: 1.0000 | [0.1791, 13.7758] | [34.7569, 17.4957]\n",
      "  08: 1.0000 | [0.5339, 20.1925] | [32.6578, 22.4218]\n",
      "  09: 1.0000 | [0.7813, 17.4160] | [41.2078, 0.5000]\n",
      "  10: 1.0000 | [0.4712, 32.9950] | [19.3703, 40.1469]\n",
      "  11: 1.0000 | [0.7049, 26.4719] | [31.7768, 0.5000]\n",
      "  12: 1.0000 | [0.4481, 17.9035] | [10.8995, 54.2379]\n",
      "  13: 1.0000 | [1.3324, 33.8258] | [9.7388, 59.9150]\n",
      "  14: 1.0000 | [1.8868, 12.0307] | [26.4693, 0.5000]\n",
      "  15: 1.0000 | [1.1012, -17.9229] | [17.3176, 78.9202]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T12:53:08.547563Z",
     "start_time": "2025-11-27T12:50:53.791348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"original stats:\")\n",
    "print_scalar_stats(model)\n",
    "sample_loss(model, total_tokens)"
   ],
   "id": "e96cd0ec9cb14f3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original stats:\n",
      "skip_weights: {'min': 0.0881648138165474, 'max': 1.0, 'mean': 0.8417758941650391, 'std': 0.3415984809398651}\n",
      "lambdas: {'min': -17.922931671142578, 'max': 52.3514404296875, 'mean': 13.798450469970703, 'std': 16.747438430786133}\n",
      "sa_lambdas: {'min': 0.5, 'max': 78.92021179199219, 'mean': 25.31561279296875, 'std': 21.081050872802734}\n",
      "{'val_loss': 2.839808146158854, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': nan}\n",
      "{'val_loss': 2.9695704778035483, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 1.297623316446943e-06}\n",
      "{'val_loss': 2.7490504582722983, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 2.4677626291911003e-07}\n",
      "{'val_loss': 2.9539562861124673, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 7.874608675638839e-07}\n",
      "{'val_loss': 2.7987181345621743, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 8.55081526438398e-08}\n",
      "{'val_loss': 2.785984992980957, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 2.165628210703595e-08}\n",
      "{'val_loss': 2.803197224934896, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 6.679609333674202e-08}\n",
      "{'val_loss': 2.7680228551228843, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': -5.876584410031575e-08}\n",
      "{'val_loss': 2.8233089447021484, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 1.247221778675715e-07}\n",
      "{'val_loss': 2.898944854736328, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 3.142132546098391e-07}\n",
      "avg loss: 2.839056237538655\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T12:53:09.112812Z",
     "start_time": "2025-11-27T12:53:08.604102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ns_model = clone_with_renormalized_scalars(model)\n",
    "report = build_report(ns_model)\n",
    "print(f\"Model report (cloned renormalized):\\n{format_report_text(report)}\")"
   ],
   "id": "e5bffa4c5c779931",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model report (cloned renormalized):\n",
      "=== Checkpoint ===\n",
      "\n",
      "=== Model stats ===\n",
      "parameters (total): 818,932,816 (818932816)\n",
      "parameters (trainable): 818,932,816 (818932816)\n",
      "parameter size: 1660.24 MiB\n",
      "model type: DaisyCore\n",
      "layers: 16\n",
      "\n",
      "parameter dtypes:\n",
      "  float32: 51,511,376 (51511376)\n",
      "  bfloat16: 767,421,440 (767421440)\n",
      "\n",
      "=== Learned scalars (DaisyCore) ===\n",
      "num_layers (inferred): 16\n",
      "threshold for near-zero: 0.001\n",
      "- skip_weights: shape=[16], min=0.08816, max=1, mean=0.8418, std=0.3308\n",
      "  near-zero: 0 elements (0.00%)\n",
      "- lambdas: shape=[16, 2], min=-0.9981, max=1, mean=0.4664, std=0.5315\n",
      "  near-zero: 0 elements (0.00%)\n",
      "- sa_lambdas: shape=[16, 2], min=0.007431, max=1, mean=0.5981, std=0.3772\n",
      "  near-zero: 0 elements (0.00%)\n",
      "\n",
      "Per-layer (i: skip | lambda | sa_lambda):\n",
      "  00: 1.0000 | [0.7175, 0.6966] | [0.6516, 0.7585]\n",
      "  01: 1.0000 | [0.0061, 1.0000] | [0.9997, 0.0251]\n",
      "  02: 0.2520 | [0.0190, 0.9998] | [0.7506, 0.6608]\n",
      "  03: 1.0000 | [0.0264, 0.9997] | [0.8144, 0.5804]\n",
      "  04: 0.1282 | [0.0235, 0.9997] | [1.0000, 0.0088]\n",
      "  05: 1.0000 | [0.0212, 0.9998] | [0.9552, 0.2960]\n",
      "  06: 0.0882 | [0.0240, 0.9997] | [1.0000, 0.0074]\n",
      "  07: 1.0000 | [0.0130, 0.9999] | [0.8932, 0.4496]\n",
      "  08: 1.0000 | [0.0264, 0.9997] | [0.8244, 0.5660]\n",
      "  09: 1.0000 | [0.0448, 0.9990] | [0.9999, 0.0121]\n",
      "  10: 1.0000 | [0.0143, 0.9999] | [0.4345, 0.9006]\n",
      "  11: 1.0000 | [0.0266, 0.9996] | [0.9999, 0.0157]\n",
      "  12: 1.0000 | [0.0250, 0.9997] | [0.1970, 0.9804]\n",
      "  13: 1.0000 | [0.0394, 0.9992] | [0.1604, 0.9870]\n",
      "  14: 1.0000 | [0.1549, 0.9879] | [0.9998, 0.0189]\n",
      "  15: 1.0000 | [0.0613, -0.9981] | [0.2143, 0.9768]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T12:55:43.107672Z",
     "start_time": "2025-11-27T12:53:09.119227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1337)\n",
    "evaluator.reset_generator()\n",
    "\n",
    "print(\"new stats:\")\n",
    "print_scalar_stats(ns_model)\n",
    "sample_loss(ns_model, total_tokens)"
   ],
   "id": "e0cc9b6c7692ab17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new stats:\n",
      "skip_weights: {'min': 0.0881648138165474, 'max': 1.0, 'mean': 0.8417758941650391, 'std': 0.3415984809398651}\n",
      "lambdas: {'min': -0.9981178045272827, 'max': 0.9999814033508301, 'mean': 0.4664236307144165, 'std': 0.5399631857872009}\n",
      "sa_lambdas: {'min': 0.007431285455822945, 'max': 0.9999724626541138, 'mean': 0.5980982780456543, 'std': 0.3832336366176605}\n",
      "{'val_loss': 13.876227060953775, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 3.3151795896879226e-05}\n",
      "{'val_loss': 13.836037953694662, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 2.3085689806038116e-05}\n",
      "{'val_loss': 13.820976257324219, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 1.6114797775115353e-05}\n",
      "{'val_loss': 13.80954360961914, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 1.1246060499465511e-05}\n",
      "{'val_loss': 13.743260701497396, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 7.673393625260625e-06}\n",
      "{'val_loss': 13.867200215657553, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 5.743194080162906e-06}\n",
      "{'val_loss': 13.700804392496744, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 3.5210483866316086e-06}\n",
      "{'val_loss': 13.728435516357422, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 2.5476272422241587e-06}\n",
      "{'val_loss': 14.023572285970053, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 2.6687493783948035e-06}\n",
      "{'val_loss': 13.968189239501953, 'val_acc': None, 'epoch': None, 'ema_dloss_per_token': 1.7019754254720636e-06}\n",
      "avg loss: 13.83742472330729\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
